#!/usr/bin/env python
# coding: utf-8

import pandas as pd
get_ipython().system('pip install pymystem3')
import re
import numpy as np
from wordcloud import WordCloud, STOPWORDS
import nltk
nltk.download("stopwords")
from nltk.corpus import stopwords
from pymystem3 import Mystem
from string import punctuation
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import wordnet
nltk.download('wordnet')
import re
from collections import defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer
import warnings
warnings.filterwarnings("ignore")


df = pd.read_csv('insta_comments.csv')
df = df.drop('Unnamed: 0', axis = 1).drop_duplicates()

def clear_comm(s):
    s = re.sub(r"‚ÇΩ", ' ', s)
    s = s.replace(r".", '')
    s = re.sub(r"\b\d(?: ?\d{2,5})\b –≥–æ–¥", '', s)
    s = re.sub(r"\b\d(?: ?\d{2,5})\b-", '', s)
    s = re.sub(r"\b\d(?: ?\d{2,5})\b –∫–≤ –º", '', s)
    s = re.sub(r"\b\d(?: ?\d{2,5})\b —Å–º", '', s)
    s = re.sub(r"–∞—Ä—Ç–∏–∫—É–ª \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"—Ä–∞–∑–º–µ—Ä \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–†–∞–∑–º–µ—Ä \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"—Å–µ–∫.\b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–ê—Ä—Ç–∏–∫—É–ª \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–†–∞–∑–º–µ—Ä—ã ‚Äì \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–æ—Ñ–∏—Å \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–ê—Ä—Ç–∏–∫—É–ª: \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–î–æ—Å—Ç–∞–≤–∫–∏ –æ—Ç \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–∞—Ä—Ç–∏–∫—É–ª-\b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"—Ä–æ—Å—Ç \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"—Å–µ–∫—Ü–∏–∏ \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"—Å–µ–∫—Ü–∏—è \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"–¶–µ–Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∏ \b\d(?: ?\d{2,5})\b", '', s)
    s = re.sub(r"2021", '', s)
    s = re.sub(r"2020", '', s)
    s = re.sub(r"2019", '', s)
    s = re.sub(r"1997", '', s)
    s = re.sub(r"666", '', s)
    s = re.sub(r"210", '', s)
    s = re.sub(r"158", '', s)
    s = re.sub(r"101", '', s)
    s = re.sub(r"106", '', s)
    s = re.sub(r"147", '', s)
    s = re.sub(r"777", '', s)
    s = re.sub(r"—Ä", ' —Ä ', s)
    s = re.sub(r"—Ä—É–±", ' —Ä—É–± ', s)
    s = re.sub(r"–ù–æ–≤–æ-–°–∞–¥–æ–≤–∞—è 305", '', s)
    
    
    return s

df['comments_p'] = df['comments'].apply(clear_comm)
def extract_price(s):
    #save the first price mentioned
    r = re.search(r"\b\d(?: ?\d{2,4})\b", s)
    if r:
        result = (str(r.group(0)).replace(" ", ""))
    else:
        result = 0
    return result

def extract_hashtag(s):
    hashtags = re.findall(r"#(\w+)", s)
    return hashtags


df['price'] = df['comments_p'].apply(extract_price)
df['hashtag'] = df['comments'].apply(extract_hashtag)
df['price'] = df.price.astype(int)
df = df[df.price!=0]
df['comments']=[re.sub(r"[-()\"#/@;:<>[] < > {}`+=~|.!?,]", " ", item) for item in df['comments']]

def clear_comm1(s):
    s = re.sub(r"üòç", ' ', s)
    s = re.sub(r"‚ù§", ' ', s)
    s = re.sub(r"üå≤", ' ', s)
    s = re.sub(r"\n", ' ', s)
    s = re.sub(r"‚ñ∂", ' ', s)
    s = re.sub(r"‚ô•Ô∏è", ' ', s)
    s = re.sub(r"#", ' ', s)
    
    
    return s
    
df['comments'] = df['comments'].apply(clear_comm1)


def extract_likes(s):
    s = re.search(r"\b\d(?: ?\d{1,4})\b", s)
    if s:
        s = (s.group(0)).replace(" ", "")
    else:
        s = 0
    
    return int(s)
df['likes'] = df['likes'].apply(extract_likes)


df_profiles = pd.read_csv('df_profiles.csv')
df_profiles = df_profiles.join(df_profiles.stats.str.split('\n',expand=True))
df_profiles.columns = ['user_id', 'stats', 'posts', '–ø—É–±–ª–∏–∫–∞—Ü–∏–∏','subscribers','–ø–æ–¥–ø–∏—Å—á–∏–∫–∏', 'subscriptions', '–ø–æ–¥–ø–∏—Å–∫–∏']
df_profiles=df_profiles.drop(['stats', '–ø—É–±–ª–∏–∫–∞—Ü–∏–∏', '–ø–æ–¥–ø–∏—Å—á–∏–∫–∏', '–ø–æ–¥–ø–∏—Å–∫–∏'], axis = 1)

def extract_zeros(s):
    s = re.sub(r"—Ç—ã—Å.", '000', s)
    s = re.sub(r"–º–ª–Ω.", '000000', s)
    s = re.sub(r",", '', s)
    s = re.sub(r" ", '', s)
    return s

df_profiles['subscribers'] = df_profiles['subscribers'].apply(extract_zeros)
df_profiles['posts'] = df_profiles.posts.apply(lambda s: int(re.sub(r" ", '', s)))
df_profiles['subscriptions'] = df_profiles.subscriptions.apply(lambda s: int(re.sub(r" ", '', s)))


df = df.merge(df_profiles, on = 'user_id')


#—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∏ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–æ–ø-—Å–ª–æ–≤
mystem = Mystem() 
russian_stopwords = stopwords.words("russian")

#Preprocess function
def preprocess_text(text):
    tokens = mystem.lemmatize(text.lower())
    tokens = [token for token in tokens if token not in russian_stopwords              and token != " "               and token.strip() not in punctuation]
    
    text = " ".join(tokens)
    
    return text

import numpy as np

df['desc_pr'] = np.nan
for i, row in enumerate(df['desc']):
    if i%1==0:
        print(i)
    df['desc_pr'][i] = preprocess_text(row)

    
df['comments_pr'] = np.nan
for i, row in enumerate(df['comments']):
    if i%1 ==0:
        print(i)
    df['comments_pr'][i] = preprocess_text(row)
    
df.to_csv('df_with_lemmas.csv')

